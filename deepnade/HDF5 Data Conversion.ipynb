{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for testing against 2 models\n",
    "\n",
    "Take X and y data and apply 10-fold cross validation. Save 8 folds as training, 1 as validation, and 1 as testing.\n",
    "Save all this in an HDF5 files (separated by class) for testing on NADE.\n",
    "Save the training/validation folds as training data and testing fold as testing data for KDE model.\n",
    "\n",
    "\n",
    "HDF5 Hierarhcy (same as Wine dataset)\n",
    "- all\n",
    "- folds\n",
    "    - 1\n",
    "        - tests\n",
    "            - 1\n",
    "        - training\n",
    "            - 1\n",
    "            - 2\n",
    "            - ...\n",
    "            - 8\n",
    "            - 9\n",
    "    - 2\n",
    "    - ...\n",
    "    - 9\n",
    "\n",
    "\n",
    "Usage:\n",
    "- Use folds/1/training/ 1 - 8 as training\n",
    "- Use folds/1/training/9 as validation\n",
    "- Use folds/1/testing/1 as testing\n",
    "\n",
    "\n",
    "HDF5 Background:\n",
    "Groups are the container mechanism by which HDF5 files are organized. From a Python perspective, they operate somewhat like dictionaries. In this case the “keys” are the names of group members, and the “values” are the members themselves (Group and Dataset) objects.\n",
    "\n",
    "From here https://docs.h5py.org/en/stable/high/group.html\n",
    "\n",
    "Pandas has a method HDFStore, but I found it would not work well. It was making 4 members for each DataFrame. so I used h5py directly\n",
    "\n",
    "the following works, at least it has the same members and structure as wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import OrderedDict \n",
    "test_path = \"/Users/marina/Documents/PhD/research/astro_research/data/testing/\"\n",
    "dpath = test_path + \"PROCESSED_DATA/\"\n",
    "\n",
    "def prettify(class_name):\n",
    "    if \"/\" in class_name:\n",
    "        class_name=class_name.replace(\"/\", \"\")\n",
    "    class_name=class_name.replace(\" \", \"_\")\n",
    "    return class_name\n",
    "\n",
    "def save_class_hdf5(class_name, X, y, output_dir):\n",
    "    \"\"\"\n",
    "    Save the X data of this class as HDF5 file\n",
    "    Returns test fold to be saved separately in joined test file.\n",
    "    \"\"\" \n",
    "    class_indices = y.loc[y['transient_type'].str.contains(class_name)].index\n",
    "    class_X = X.iloc[class_indices]\n",
    "\n",
    "    # Divide data into 10 folds; use 8 as training, 1 as validation, 1 as testing\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    fold_sets = []\n",
    "    for remaining_indices, fold_indices in kf.split(class_X):\n",
    "        fold_sets.append(fold_indices)\n",
    "    training_folds=[]\n",
    "    for i in range(8):\n",
    "        training_folds.append(class_X.iloc[fold_sets[i]])\n",
    "\n",
    "    val_fold = class_X.iloc[fold_sets[8]]\n",
    "    test_fold = class_X.iloc[fold_sets[9]]\n",
    "    \n",
    "    # Save to HDF5 File \n",
    "    thex_data_path = output_dir + prettify(class_name) + 'X.hdf5'\n",
    "    hfile = h5py.File(thex_data_path, 'w')\n",
    "    # define & fill groups\n",
    "    for i in range(8):\n",
    "        training = hfile.create_group(\"folds/1/training/\" + str(i+1))\n",
    "        data = training_folds[i].to_numpy(dtype=np.float32)\n",
    "        dset = training.create_dataset(\"data\", data=data)\n",
    "    val = hfile.create_group(\"folds/1/training/9\")\n",
    "    dset = val.create_dataset(\"data\", data=val_fold.to_numpy(dtype=np.float32))\n",
    "    val = hfile.create_group(\"folds/1/tests/1\")\n",
    "    dset = val.create_dataset(\"data\", data=test_fold.to_numpy(dtype=np.float32))\n",
    "    hfile.close()\n",
    "    \n",
    "    # Also save as CSVs - to test on KDE Model\n",
    "    train_indices = []\n",
    "    for i in range(9): # Include validation fold in training\n",
    "        train_indices += fold_sets[i].tolist() \n",
    "    class_train = class_X.iloc[train_indices]\n",
    "    class_test = class_X.iloc[fold_sets[9]]\n",
    "    class_train.to_csv(output_dir + prettify(class_name) + \"train.csv\", index=False)\n",
    "    class_test.to_csv(output_dir + prettify(class_name) + \"test.csv\", index=False)\n",
    "    return test_fold\n",
    "\n",
    " \n",
    "def save_test_sets(test_folds, dpath):\n",
    "    \"\"\"\n",
    "    Using existing folds, combine each class's test fold into one whole test data set.\n",
    "    Save as both an HDF5 and CSV. \n",
    "    \"\"\"\n",
    "    full_test_set = pd.concat(test_folds.values())\n",
    "    hfile = h5py.File(dpath + \"test_X.hdf5\", 'w')\n",
    "    group = hfile.create_group(\"folds/1/tests/1\")\n",
    "    dset = group.create_dataset(\"data\", data=full_test_set.to_numpy(dtype=np.float32))\n",
    "    hfile.close()\n",
    "    # Save as CSV too for KDE model testing\n",
    "    full_test_set.to_csv(dpath + \"test_X.csv\", index=False)\n",
    "\n",
    "    # Save labels corresponding to test set in CSV.\n",
    "    labels = []\n",
    "    for class_name in test_folds.keys():\n",
    "        class_count = test_folds[class_name].shape[0]\n",
    "        for i in range (class_count):\n",
    "            labels.append(class_name)\n",
    "    label_df = pd.DataFrame(labels, columns=[\"transient_type\"])\n",
    "    label_df.to_csv(dpath+\"test_y.csv\",index=False)\n",
    "\n",
    "def save_train_X_y(dpath, classes):\n",
    "    \"\"\"\n",
    "    Load train X CSV files, and combine all into one X training file\n",
    "    Save labels in correct order in corresponding y file.\n",
    "    For use in KDE model.\n",
    "    \"\"\"\n",
    "    class_dfs = []\n",
    "    labels = []\n",
    "    for class_name in classes:\n",
    "        class_X = pd.read_csv(dpath + prettify(class_name) + \"train.csv\")\n",
    "        class_dfs.append(class_X)\n",
    "        for i in range(class_X.shape[0]):\n",
    "            labels.append(class_name)\n",
    "    X = pd.concat(class_dfs)\n",
    "    X.to_csv(dpath + \"train_X.csv\", index=False)\n",
    "    pd.DataFrame(labels, columns = ['transient_type']).to_csv(dpath + \"train_y.csv\", index=False)\n",
    "\n",
    "# CONSTS\n",
    "# classes = ['Unspecified Ia', 'Unspecified Ia Pec', 'Ia-91T', 'Ia-91bg', 'Ib/c', 'Unspecified Ib', 'IIb', \n",
    "#            'Unspecified Ic', 'Ic Pec', 'Unspecified II', 'II P', 'IIn', 'TDE', 'GRB']\n",
    "classes = ['Unspecified Ia', 'Unspecified II']\n",
    "\n",
    "#  Data Note\n",
    "#  The following data comes from an initialized THEx MultiModel. \n",
    "#  So, it represents all rows that have valid values for the mags and colors\n",
    "X = pd.read_csv(test_path + \"X.csv\")\n",
    "y = pd.read_csv(test_path + \"y.csv\")\n",
    "\n",
    "# Save each class to separate HDF5 file to train on \n",
    "test_folds = OrderedDict()\n",
    "for class_name in classes:\n",
    "    test_folds[class_name] = save_class_hdf5(class_name, X, y, dpath)\n",
    "\n",
    "save_test_sets(test_folds, dpath)\n",
    "\n",
    "save_train_X_y(dpath, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init BigDataset with THEx HDF5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "\n",
    "dpath = \"/Users/marina/Documents/PhD/research/astro_research/data/testing/\"\n",
    "thex_data_path = dpath + \"Unspecified_IaX.hdf5\"\n",
    "\n",
    "# os.environ[\"DATASETSPATH\"]=\"\"\n",
    "# data_source = \"red_wine.hdf5\"\n",
    "# dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "dataset_file = thex_data_path\n",
    "training_dataset = Data.BigDataset(dataset_file, \n",
    "                                   \"/folds/1/training/(1|2|3|4|5|6|7|8)\", \n",
    "                                   \"data\") \n",
    "testing_dataset = Data.BigDataset(dataset_file, \"/folds/1/tests/.*\", \"data\")\n",
    "validation_dataset = Data.BigDataset(dataset_file, \"/folds/1/training/9\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset.sample_data(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Dataset Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcomes\n",
    "\n",
    "1. 159 samples in each training fold\n",
    "2. 168 in validation \n",
    "3. 159 in testing\n",
    "\n",
    "There is OVERLAP among all 3. So testing data inside of training and validation.\n",
    "46/159 testing samples in the whole training set\n",
    "9/159 testing samples in validation \n",
    "\n",
    "And overlap in training/validation.\n",
    "\n",
    "wine dataset HDF5 data has the following hierarchy:\n",
    "- all\n",
    "- folds\n",
    "    - 1\n",
    "        - tests\n",
    "            - 1\n",
    "        - training\n",
    "            - 1\n",
    "            - 2\n",
    "            - ...\n",
    "            - 8\n",
    "            - 9\n",
    "    - 2\n",
    "    - ...\n",
    "    - 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine if there is any data overlap in training/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "os.environ[\"DATASETSPATH\"]=\"\"\n",
    "data_source = \"red_wine.hdf5\"\n",
    "training = \"/folds/1/training/(1|2|3|4|5|6|7|8)\"\n",
    "dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "training_dataset = Data.BigDataset(dataset_file, training, \"data\")\n",
    "testing_dataset = Data.BigDataset(dataset_file, \"/folds/1/tests/.*\", \"data\")\n",
    "validation_dataset = Data.BigDataset(dataset_file, \"/folds/1/training/9\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=testing_dataset.get_file(0, 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.T\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.atleast_2d(a).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure no testing/training/validation overlaps\n",
    "training_indices= [0,1,2,3,4,5,6,7]\n",
    "validation_index = [8]\n",
    "\n",
    "test_overlap_count = 0\n",
    "for i in range(testing_fold.shape[0]):\n",
    "    test_sample = testing_fold[i]\n",
    "    # No overlap with training/testing\n",
    "    total_training = 0 #to keep track of later.\n",
    "    for ti in training_indices:\n",
    "        training_fold = training_dataset.get_file(element = 0, index= ti)\n",
    "        for row in training_fold:\n",
    "            total_training +=1\n",
    "            if (row == test_sample).all():\n",
    "                test_overlap_count+=1\n",
    "print(\"Overlap in testing and training \" + str(test_overlap_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap with validation/testing\n",
    "validation_fold = validation_dataset.get_file(element = 0, index= 0)\n",
    "val_overlap_count = 0\n",
    "for i in range(testing_fold.shape[0]):\n",
    "    test_sample = testing_fold[i]\n",
    "    for row in validation_fold:\n",
    "        if (row == test_sample).all():\n",
    "            val_overlap_count+=1\n",
    "print(\"Overlap in validation and testing \" + str(val_overlap_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap with training/validation\n",
    "matching_rows=0\n",
    "for i in range(validation_fold.shape[0]):\n",
    "    validation_sample = validation_fold[i]\n",
    "    for ti in training_indices:\n",
    "        training_fold = training_dataset.get_file(element = 0, index= ti)\n",
    "        for row in training_fold:\n",
    "            if (row == validation_sample).all():\n",
    "                matching_rows +=1\n",
    "print(\"Number of matching rows in validation + training \" + str(matching_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total rows in training \" + str(total_training))\n",
    "print(\"Total rows in validation \" + str(validation_fold.shape[0]))\n",
    "print(\"Total rows in testing \" + str(testing_fold.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually pulling down wine-dataset and manually examining entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "wine_f = h5py.File(\"red_wine.hdf5\", \"r\")\n",
    "# wine_f[\"/\"]\n",
    "\n",
    "print(wine_f.name)\n",
    "print(wine_f.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "element_names=\"data\"\n",
    "element_names = element_names if isinstance(element_names, tuple) else (element_names,)\n",
    "\n",
    "# entries_regexp = \"/folds/1/training/(1|2|3|4|5|6|7|8)\" # Training \n",
    "# entries_regexp=\"/folds/1/tests/.*\"  # Testing \n",
    "entries_regexp = \"/folds/1/training/9\"  # Validation \n",
    "pats = entries_regexp.split(\"/\")\n",
    "pats.remove(\"\")\n",
    "\n",
    "\"\"\"\n",
    "Coming up with entries:\n",
    "\n",
    "We pass in \"/folds/1/training/(1|2|3|4|5|6|7|8)\" as the 'entries_regexp' \n",
    "so we are saying to use folds 1-8 for training\n",
    "\n",
    "So, it selects the parts of the HDF5 dataset that are located at the part of the hierarhcy we\n",
    "are selecting, using the regexp. \n",
    "\n",
    "- Use folds/1/training/ 1 - 8 as training\n",
    "- Use folds/1/training/9 as validation\n",
    "- Use folds/1/testing/1 as testing\n",
    "\n",
    "\"\"\" \n",
    "import re\n",
    "entries = [wine_f[\"/\"]] \n",
    "for p in pats:\n",
    "    new_entries = []\n",
    "    for r in entries:\n",
    "        for k, v in r.items(): \n",
    "            # Seeing if value of this HDF5 is one of the desired patterns\n",
    "            if re.match(\"^%s$\" % p, str(k)):\n",
    "                new_entries.append(v)\n",
    "    entries = new_entries \n",
    "entries\n",
    "\n",
    "#### The above does the exact same thing as:\n",
    "# entries = [wine_f[\"/\"]]\n",
    "# for p in pats:\n",
    "#     entries = [v for r in entries for k,\n",
    "#                v in r.items() if re.match(\"^%s$\" % p, str(k))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match HDF5 Data to Wine dataset on Kaggle site\n",
    "This is to ensure these are the same dataset, and they do appear to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTCOME:\n",
    "\n",
    "Data comes from wine dataset from Kaggle\n",
    "Input variables (based on physicochemical tests):\n",
    "1. fixed acidity (tartaric acid - g / dm^3)\n",
    "2. volatile acidity (acetic acid - g / dm^3)\n",
    "3. citric acid (g / dm^3)\n",
    "4. residual sugar (g / dm^3)\n",
    "5. chlorides (sodium chloride - g / dm^3\n",
    "6. free sulfur dioxide (mg / dm^3)\n",
    "7. total sulfur dioxide (mg / dm^3)\n",
    "8. density (g / cm^3)\n",
    "9. pH\n",
    "10. sulphates (potassium sulphate - g / dm3)\n",
    "11. alcohol (% by volume)\n",
    "\n",
    "Output variable (based on sensory data): \n",
    "1. quality (score between 0 and 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "os.environ[\"DATASETSPATH\"]=\"\"\n",
    "data_source = \"red_wine.hdf5\"\n",
    "training = \"/folds/1/training/(1|2|3|4|5|6|7|8)\"\n",
    "dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "training_dataset = Data.BigDataset(dataset_file, training, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample row and see if it is in other dataset\n",
    "training_fold_0 = training_dataset.get_file(element = 0, index= 0)\n",
    "sample_row = training_fold_0[0]\n",
    "sample_row.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine_test_path = \"~/Documents/PhD/research/astro_research/data/testing/wineQualityReds.csv\"\n",
    "wine_dataset = pd.read_csv(wine_test_path)\n",
    "\n",
    "train_wine_dataset = wine_dataset.drop(columns=['Unnamed: 0', 'quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for index, row in train_wine_dataset.iterrows():\n",
    "    \n",
    "    rtol = 1e-05\n",
    "    atol = 1e-08\n",
    "    res = np.allclose(sample_row, row, rtol, atol) \n",
    "    if res:\n",
    "        print(row)\n",
    "        print(\"Row index match: \" + str(index))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options, args =parser.parse_args([\"--theano\", \n",
    "#                                   \"--form\", \"MoG\", \n",
    "#                                   \"--dataset\", \"red_wine.hdf5\", \n",
    "#                                   \"--training_route\", \"/folds/1/training/(1|2|3|4|5|6|7|8)\",\n",
    "#                                  \"--validation_route\", \"/folds/1/training/9\",\n",
    "#                                  \"--test_route\", \"/folds/1/tests/.*\",\n",
    "#                                  \"--samples_name\", \"data\",\n",
    "#                                  \"--hlayers\", \"2\", # 2 hidden layers\n",
    "#                                   \"--layerwise\",\n",
    "#                                   \"--lr\", \"0.02\",\n",
    "#                                   \"--wd\", \"0.02\",\n",
    "#                                   \"--n_components\", \"10\",\n",
    "#                                   \"--epoch_size\", \"100\",\n",
    "#                                   \"--momentum\", \"0.9\",\n",
    "#                                   \"--units\", \"100\",\n",
    "#                                   \"--pretraining_epochs\", \"5\",\n",
    "#                                   \"--validation_loops\", \"20\",\n",
    "#                                   \"--epochs\", \"20\",\n",
    "#                                   \"--normalize\",\n",
    "#                                   \"--batch_size\", \"100\",\n",
    "#                                   \"--show_training_stop\", \"red_wine\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nade",
   "language": "python",
   "name": "nade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
