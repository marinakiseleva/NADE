{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert THEx Data to HDF5\n",
    "1. load CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# \n",
    "#  Data Note\n",
    "#  The following data comes from an initialized THEx MultiModel. \n",
    "#  So, it represents all rows that have valid values for the mags and colors\n",
    "#  \n",
    "dpath = \"/Users/marina/Documents/PhD/research/astro_research/data/testing/\"\n",
    "# Load CSVs of X and y\n",
    "X = pd.read_csv(dpath + \"X.csv\")\n",
    "y = pd.read_csv(dpath + \"y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to HDF5 with same format as WINE dataset\n",
    "Hierarhcy:\n",
    "- all\n",
    "- folds\n",
    "    - 1\n",
    "        - tests\n",
    "            - 1\n",
    "        - training\n",
    "            - 1\n",
    "            - 2\n",
    "            - ...\n",
    "            - 8\n",
    "            - 9\n",
    "    - 2\n",
    "    - ...\n",
    "    - 9\n",
    "\n",
    "\n",
    "Usage:\n",
    "\n",
    "- Use folds/1/training/ 1 - 8 as training\n",
    "- Use folds/1/training/9 as validation\n",
    "- Use folds/1/testing/1 as testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X of certain class to HDF5 File\n",
    "class_name = \"Unspecified Ia\"\n",
    "class_indices = y.loc[y['transient_type'].str.contains(class_name)].index\n",
    "class_X = X.iloc[class_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into folds, randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "fold_sets = []\n",
    "for remaining_indices, fold_indices in kf.split(class_X):\n",
    "    fold_sets.append(fold_indices)\n",
    "training_folds=[]\n",
    "for i in range(8):\n",
    "    training_folds.append(class_X.iloc[fold_sets[i]])\n",
    "\n",
    "val_fold = class_X.iloc[fold_sets[8]]\n",
    "test_fold = class_X.iloc[fold_sets[9]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6366318e+01,  1.6295883e+01,  1.6851646e+01, ...,\n",
       "        -3.8579464e-01, -2.8179741e-01, -1.3949776e-01],\n",
       "       [ 1.2880881e+01,  1.2980280e+01,  1.3428139e+01, ...,\n",
       "        -3.9757919e-01, -1.8321991e-01, -2.0078182e-01],\n",
       "       [ 1.6922680e+01,  1.7184122e+01,  1.7317171e+01, ...,\n",
       "        -3.0387878e-01, -1.0267487e+00, -2.3467064e-01],\n",
       "       ...,\n",
       "       [ 1.3286318e+01,  1.3557161e+01,  1.3875146e+01, ...,\n",
       "        -4.1408443e-01, -1.9860840e-01, -2.0015907e-01],\n",
       "       [ 1.9503904e+01,  1.9722898e+01,  1.9776192e+01, ...,\n",
       "        -1.9147301e-01,  1.1680794e-01,  2.4200630e-01],\n",
       "       [ 1.8643970e+01,  1.8365751e+01,  1.9170395e+01, ...,\n",
       "         2.1871376e-01, -7.4825287e-03, -4.9394608e-02]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.float32\n",
    "test_fold.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 Background\n",
    "Groups are the container mechanism by which HDF5 files are organized. From a Python perspective, they operate somewhat like dictionaries. In this case the “keys” are the names of group members, and the “values” are the members themselves (Group and Dataset) objects.\n",
    "\n",
    "From here https://docs.h5py.org/en/stable/high/group.html\n",
    "\n",
    "Pandas has a method HDFStore, but I found it would not work well. It was making 4 members for each DataFrame. so I used h5py directly\n",
    "\n",
    "the following works, at least it has the same members and structure as wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Unable to create file (unable to truncate a file which is already open)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fa543c0413bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthex_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'X.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthex_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marina/Documents/PhD/research/astro_research/code/environments/nade_env/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/marina/Documents/PhD/research/astro_research/code/environments/nade_env/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to create file (unable to truncate a file which is already open)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "thex_data_path = dpath + class_name.replace(\" \", \"_\") + 'X.hdf5'\n",
    "\n",
    "hfile = h5py.File(thex_data_path, 'w')\n",
    "\n",
    "\n",
    "# define & fill groups\n",
    "for i in range(8):\n",
    "    training = hfile.create_group(\"folds/1/training/\" + str(i+1))\n",
    "    data = training_folds[i].to_numpy(dtype=np.float32)\n",
    "    dset = training.create_dataset(\"data\", data=data)\n",
    "\n",
    "    \n",
    "val = hfile.create_group(\"folds/1/training/9\")\n",
    "dset = val.create_dataset(\"data\", data=val_fold.to_numpy(dtype=np.float32))\n",
    "    \n",
    "\n",
    "val = hfile.create_group(\"folds/1/tests/1\")\n",
    "dset = val.create_dataset(\"data\", data=test_fold.to_numpy(dtype=np.float32))\n",
    "\n",
    "\n",
    "hfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init BigDataset with THEx HDF5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " BigDataset Working on /Users/marina/Documents/PhD/research/astro_research/data/testing/Unspecified_IaX.hdf5\n",
      "Entries /folds/1/training/(1|2|3|4|5|6|7|8)\n",
      "\n",
      "\n",
      " BigDataset Working on /Users/marina/Documents/PhD/research/astro_research/data/testing/Unspecified_IaX.hdf5\n",
      "Entries /folds/1/tests/.*\n",
      "\n",
      "\n",
      " BigDataset Working on /Users/marina/Documents/PhD/research/astro_research/data/testing/Unspecified_IaX.hdf5\n",
      "Entries /folds/1/training/9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "\n",
    "dpath = \"/Users/marina/Documents/PhD/research/astro_research/data/testing/\"\n",
    "thex_data_path = dpath + \"Unspecified_IaX.hdf5\"\n",
    "\n",
    "# os.environ[\"DATASETSPATH\"]=\"\"\n",
    "# data_source = \"red_wine.hdf5\"\n",
    "# dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "dataset_file = thex_data_path\n",
    "training_dataset = Data.BigDataset(dataset_file, \n",
    "                                   \"/folds/1/training/(1|2|3|4|5|6|7|8)\", \n",
    "                                   \"data\") \n",
    "testing_dataset = Data.BigDataset(dataset_file, \"/folds/1/tests/.*\", \"data\")\n",
    "validation_dataset = Data.BigDataset(dataset_file, \"/folds/1/training/9\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[16.976038  , 17.019712  , 17.436167  , 17.2412    , 17.660822  ,\n",
       "         16.198233  , 18.533974  , 16.52771   , 16.403433  , 16.841549  ,\n",
       "          0.7778053 , -0.22148705,  0.46012878, -0.41962242, -0.8731518 ,\n",
       "         -0.2052002 , -0.31383896, -0.12427711, -0.17816353],\n",
       "        [13.7143755 , 14.08379   , 14.070934  , 14.294066  , 14.621517  ,\n",
       "         13.278459  , 15.238683  , 13.500901  , 13.16716   , 13.851856  ,\n",
       "          0.4359169 , -0.2102766 ,  0.3565588 , -0.32745075, -0.61716557,\n",
       "          0.11129856, -0.350955  , -0.3337412 , -0.2319336 ],\n",
       "        [17.156197  , 17.688894  , 17.606287  , 17.89682   , 18.546644  ,\n",
       "         16.648182  , 19.960075  , 17.252419  , 16.703648  , 17.818108  ,\n",
       "          0.5080147 , -0.2079258 ,  0.4500904 , -0.64982414, -1.4134312 ,\n",
       "         -0.0554657 , -0.5656891 , -0.5487709 ,  0.12921333]],\n",
       "       dtype=float32),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset.sample_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Dataset Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcomes\n",
    "\n",
    "1. 159 samples in each training fold\n",
    "2. 168 in validation \n",
    "3. 159 in testing\n",
    "\n",
    "There is OVERLAP among all 3. So testing data inside of training and validation.\n",
    "46/159 testing samples in the whole training set\n",
    "9/159 testing samples in validation \n",
    "\n",
    "And overlap in training/validation.\n",
    "\n",
    "wine dataset HDF5 data has the following hierarchy:\n",
    "- all\n",
    "- folds\n",
    "    - 1\n",
    "        - tests\n",
    "            - 1\n",
    "        - training\n",
    "            - 1\n",
    "            - 2\n",
    "            - ...\n",
    "            - 8\n",
    "            - 9\n",
    "    - 2\n",
    "    - ...\n",
    "    - 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine if there is any data overlap in training/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " BigDataset Working on red_wine.hdf5\n",
      "Entries /folds/1/training/(1|2|3|4|5|6|7|8)\n",
      "\n",
      "\n",
      " BigDataset Working on red_wine.hdf5\n",
      "Entries /folds/1/tests/.*\n",
      "\n",
      "\n",
      " BigDataset Working on red_wine.hdf5\n",
      "Entries /folds/1/training/9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "os.environ[\"DATASETSPATH\"]=\"\"\n",
    "data_source = \"red_wine.hdf5\"\n",
    "training = \"/folds/1/training/(1|2|3|4|5|6|7|8)\"\n",
    "dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "training_dataset = Data.BigDataset(dataset_file, training, \"data\")\n",
    "testing_dataset = Data.BigDataset(dataset_file, \"/folds/1/tests/.*\", \"data\")\n",
    "validation_dataset = Data.BigDataset(dataset_file, \"/folds/1/training/9\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=testing_dataset.get_file(0, 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=a.T\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.880881  ],\n",
       "       [12.98028   ],\n",
       "       [13.428139  ],\n",
       "       [13.180984  ],\n",
       "       [13.500116  ],\n",
       "       [12.357191  ],\n",
       "       [14.06948   ],\n",
       "       [12.381919  ],\n",
       "       [12.198699  ],\n",
       "       [12.779498  ],\n",
       "       [ 0.5236902 ],\n",
       "       [-0.20070362],\n",
       "       [ 0.5472574 ],\n",
       "       [-0.3191328 ],\n",
       "       [-0.5693636 ],\n",
       "       [ 0.15849209],\n",
       "       [-0.3975792 ],\n",
       "       [-0.18321991],\n",
       "       [-0.20078182]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.atleast_2d(a).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure no testing/training/validation overlaps\n",
    "training_indices= [0,1,2,3,4,5,6,7]\n",
    "validation_index = [8]\n",
    "\n",
    "test_overlap_count = 0\n",
    "for i in range(testing_fold.shape[0]):\n",
    "    test_sample = testing_fold[i]\n",
    "    # No overlap with training/testing\n",
    "    total_training = 0 #to keep track of later.\n",
    "    for ti in training_indices:\n",
    "        training_fold = training_dataset.get_file(element = 0, index= ti)\n",
    "        for row in training_fold:\n",
    "            total_training +=1\n",
    "            if (row == test_sample).all():\n",
    "                test_overlap_count+=1\n",
    "print(\"Overlap in testing and training \" + str(test_overlap_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap with validation/testing\n",
    "validation_fold = validation_dataset.get_file(element = 0, index= 0)\n",
    "val_overlap_count = 0\n",
    "for i in range(testing_fold.shape[0]):\n",
    "    test_sample = testing_fold[i]\n",
    "    for row in validation_fold:\n",
    "        if (row == test_sample).all():\n",
    "            val_overlap_count+=1\n",
    "print(\"Overlap in validation and testing \" + str(val_overlap_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap with training/validation\n",
    "matching_rows=0\n",
    "for i in range(validation_fold.shape[0]):\n",
    "    validation_sample = validation_fold[i]\n",
    "    for ti in training_indices:\n",
    "        training_fold = training_dataset.get_file(element = 0, index= ti)\n",
    "        for row in training_fold:\n",
    "            if (row == validation_sample).all():\n",
    "                matching_rows +=1\n",
    "print(\"Number of matching rows in validation + training \" + str(matching_rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total rows in training \" + str(total_training))\n",
    "print(\"Total rows in validation \" + str(validation_fold.shape[0]))\n",
    "print(\"Total rows in testing \" + str(testing_fold.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually pulling down wine-dataset and manually examining entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "wine_f = h5py.File(\"red_wine.hdf5\", \"r\")\n",
    "# wine_f[\"/\"]\n",
    "\n",
    "print(wine_f.name)\n",
    "print(wine_f.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "element_names=\"data\"\n",
    "element_names = element_names if isinstance(element_names, tuple) else (element_names,)\n",
    "\n",
    "# entries_regexp = \"/folds/1/training/(1|2|3|4|5|6|7|8)\" # Training \n",
    "# entries_regexp=\"/folds/1/tests/.*\"  # Testing \n",
    "entries_regexp = \"/folds/1/training/9\"  # Validation \n",
    "pats = entries_regexp.split(\"/\")\n",
    "pats.remove(\"\")\n",
    "\n",
    "\"\"\"\n",
    "Coming up with entries:\n",
    "\n",
    "We pass in \"/folds/1/training/(1|2|3|4|5|6|7|8)\" as the 'entries_regexp' \n",
    "so we are saying to use folds 1-8 for training\n",
    "\n",
    "So, it selects the parts of the HDF5 dataset that are located at the part of the hierarhcy we\n",
    "are selecting, using the regexp. \n",
    "\n",
    "- Use folds/1/training/ 1 - 8 as training\n",
    "- Use folds/1/training/9 as validation\n",
    "- Use folds/1/testing/1 as testing\n",
    "\n",
    "\"\"\" \n",
    "import re\n",
    "entries = [wine_f[\"/\"]] \n",
    "for p in pats:\n",
    "    new_entries = []\n",
    "    for r in entries:\n",
    "        for k, v in r.items(): \n",
    "            # Seeing if value of this HDF5 is one of the desired patterns\n",
    "            if re.match(\"^%s$\" % p, str(k)):\n",
    "                new_entries.append(v)\n",
    "    entries = new_entries \n",
    "entries\n",
    "\n",
    "#### The above does the exact same thing as:\n",
    "# entries = [wine_f[\"/\"]]\n",
    "# for p in pats:\n",
    "#     entries = [v for r in entries for k,\n",
    "#                v in r.items() if re.match(\"^%s$\" % p, str(k))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match HDF5 Data to Wine dataset on Kaggle site\n",
    "This is to ensure these are the same dataset, and they do appear to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTCOME:\n",
    "\n",
    "Data comes from wine dataset from Kaggle\n",
    "Input variables (based on physicochemical tests):\n",
    "1. fixed acidity (tartaric acid - g / dm^3)\n",
    "2. volatile acidity (acetic acid - g / dm^3)\n",
    "3. citric acid (g / dm^3)\n",
    "4. residual sugar (g / dm^3)\n",
    "5. chlorides (sodium chloride - g / dm^3\n",
    "6. free sulfur dioxide (mg / dm^3)\n",
    "7. total sulfur dioxide (mg / dm^3)\n",
    "8. density (g / cm^3)\n",
    "9. pH\n",
    "10. sulphates (potassium sulphate - g / dm3)\n",
    "11. alcohol (% by volume)\n",
    "\n",
    "Output variable (based on sensory data): \n",
    "1. quality (score between 0 and 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append('buml') \n",
    "import os\n",
    "import Data.utils\n",
    "os.environ[\"DATASETSPATH\"]=\"\"\n",
    "data_source = \"red_wine.hdf5\"\n",
    "training = \"/folds/1/training/(1|2|3|4|5|6|7|8)\"\n",
    "dataset_file = os.path.join(os.environ[\"DATASETSPATH\"], data_source)\n",
    "training_dataset = Data.BigDataset(dataset_file, training, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample row and see if it is in other dataset\n",
    "training_fold_0 = training_dataset.get_file(element = 0, index= 0)\n",
    "sample_row = training_fold_0[0]\n",
    "sample_row.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wine_test_path = \"~/Documents/PhD/research/astro_research/data/testing/wineQualityReds.csv\"\n",
    "wine_dataset = pd.read_csv(wine_test_path)\n",
    "\n",
    "train_wine_dataset = wine_dataset.drop(columns=['Unnamed: 0', 'quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for index, row in train_wine_dataset.iterrows():\n",
    "    \n",
    "    rtol = 1e-05\n",
    "    atol = 1e-08\n",
    "    res = np.allclose(sample_row, row, rtol, atol) \n",
    "    if res:\n",
    "        print(row)\n",
    "        print(\"Row index match: \" + str(index))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options, args =parser.parse_args([\"--theano\", \n",
    "#                                   \"--form\", \"MoG\", \n",
    "#                                   \"--dataset\", \"red_wine.hdf5\", \n",
    "#                                   \"--training_route\", \"/folds/1/training/(1|2|3|4|5|6|7|8)\",\n",
    "#                                  \"--validation_route\", \"/folds/1/training/9\",\n",
    "#                                  \"--test_route\", \"/folds/1/tests/.*\",\n",
    "#                                  \"--samples_name\", \"data\",\n",
    "#                                  \"--hlayers\", \"2\", # 2 hidden layers\n",
    "#                                   \"--layerwise\",\n",
    "#                                   \"--lr\", \"0.02\",\n",
    "#                                   \"--wd\", \"0.02\",\n",
    "#                                   \"--n_components\", \"10\",\n",
    "#                                   \"--epoch_size\", \"100\",\n",
    "#                                   \"--momentum\", \"0.9\",\n",
    "#                                   \"--units\", \"100\",\n",
    "#                                   \"--pretraining_epochs\", \"5\",\n",
    "#                                   \"--validation_loops\", \"20\",\n",
    "#                                   \"--epochs\", \"20\",\n",
    "#                                   \"--normalize\",\n",
    "#                                   \"--batch_size\", \"100\",\n",
    "#                                   \"--show_training_stop\", \"red_wine\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nade",
   "language": "python",
   "name": "nade"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
